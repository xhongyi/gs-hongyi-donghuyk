\section{Analysis} \label{sec:analysis} 

As it is shown in Result section, Adjacency filtering reduces the number of
edit-distance performed a lot.  However, as the adjacency filtering will always
test if N – e segments find corresponding locations, the effectiveness of
adjacency filtering is related to the user-set error tolerance number e. As e
increases, the effectiveness of adjacency filtering decreases, since the
required number of matching segments is reduced. To maintain the adjacency
filtering effectiveness, one solution will be using shorter key for hash table
thus cut the fragments into shorter segments and increasing the segments count.
For example, if the fragment is 108 base-pairs in length and each segment is 12
base-pair in length so we cut the fragment into 9 segments, for a user set
error tolerance number e=5, instead of requiring N-e = 9-5 = 4 segments find
corresponding adjacent locations, we now reduce the key length to 9 which will
divide the fragment into 12 segments, and we will require N-e = 12-5 = 7
segments finding corresponding adjacent locations. We have simulated 9 case for
1 chromosome and it turns out when e=5, setting key length to 9 does increase
the effectiveness of adjacency filtering where it is filtering out more not
matching locations. However, we do see a longer execution time. The reason is
that although the adjacency filtering effectiveness is enhanced, the cost of
adjacency filtering is increased. Since now the keys are shorter in hash table
and the entries are fewer while the total number of coordinates stays the same
as before, the coordinate list for each hash table entry is increased. As a
result, adjacency filtering will need to reverse more coordinates. To make it
even worse, now there are more segments and thus more searching for
corresponding adjacent coordinates. Last but not the least, this increase the
chance of encountering “popular” keys with the same reason we described in
Algorithm section, as now we are having less entries but longer coordinate
list. In all, this reduces the execution time a lot. In figure 7, we show when
changing key length from 12 to 9. How many coordinate are subjects to adjacency
filtering compared to before. In figure 8, we show the increased effectiveness
of adjacency filtering since less coordinates will be subject to edit-distance
calculation and figure 9 shows the increased execution time. \\ 

For cheap key selection, we face the same problem.  Since we are picking the
cheapest N-e+1 keys. As e increases, the keys we pick will become less
\textit{cheap}. When e = N-1, the program will just behave as if without cheap
key selection, since it is picking all the keys anyhow. We can increase the
chance of picking relatively cheap keys by the same trick as above: smaller key
length and more segments. However, by also same with the reason listed above,
increasing the key number does not necessarily provides speed up. Although we
increase the chance picking relatively cheap keys, since the coordinate list is
longer now, the now \textit{cheap} keys’ coordinate list are actually longer
than before. We modeled key length 9 case, and the result is the shown in
figure 7 as well. \\ 

In reality, normally error tolerance e is set to 5\% of the fragment sequence
length. For a 108 read, e will normally be 5, by which FashHASH still provides
generally considerable speed up. However, as e increases, the performance
improvement will diminish, because of the reason stated above. \\
